{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Explicaciones de los modelos\n",
    "* Implementar matriz de confusion para poder ver de forma más visual los casos buenos y malos\n",
    "* Label encoder\n",
    "* Posibles implementaciones: \n",
    "> * Regresión logística con CountVectorizer y TFid\n",
    "> * Decision Tree vs Random forest\n",
    "> * Word Embedding text vs titles?\n",
    "> * Algún modelo de Deep learning (GPT-2, GPT-3 (IMPOSIBLE), BERT (BETO EN ESPAÑOL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "##Spacy function\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "##\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "##ver rendimiento\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tendencias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tecnologias</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pais</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mundo</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deportes</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cultura</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  count(*)\n",
       "0   tendencias      1000\n",
       "1  tecnologias      1000\n",
       "2         pais      1000\n",
       "3        mundo      1000\n",
       "4     economia      1000\n",
       "5     deportes      1000\n",
       "6      cultura      1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cnnchile_7000.csv')\n",
    "df = df.drop([\"country\",\"media_outlet\", \"url\",\"date\",\"title\"],1)\n",
    "\n",
    "q=\"\"\"SELECT category, count(*) FROM df GROUP BY category ORDER BY count(*) DESC;\"\"\"\n",
    "result=sqldf(q)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Tests textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=\"\"\"SELECT * FROM df WHERE category = \"tendencias\";\"\"\"\n",
    "df_tend=sqldf(q)\n",
    "\n",
    "df_tend = df_tend.sample(n=300)\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"tecnologias\";\"\"\"\n",
    "df_tech = sqldf(q)\n",
    "\n",
    "df_tech = df_tech.sample(n=300)\n",
    "\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"pais\";\"\"\"\n",
    "df_pais=sqldf(q)\n",
    "\n",
    "df_pais = df_pais.sample(n=300)\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"mundo\";\"\"\"\n",
    "df_mundo=sqldf(q)\n",
    "\n",
    "df_mundo = df_mundo.sample(n=300)\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"economia\";\"\"\"\n",
    "df_eco=sqldf(q)\n",
    "\n",
    "df_eco = df_eco.sample(n=300)\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"deportes\";\"\"\"\n",
    "df_dep = sqldf(q)\n",
    "\n",
    "df_dep = df_dep.sample(n=300)\n",
    "\n",
    "q=\"\"\"SELECT * FROM df WHERE category = \"cultura\";\"\"\"\n",
    "df_cult = sqldf(q)\n",
    "\n",
    "df_cult = df_cult.sample(n=300)\n",
    "\n",
    "df_train = pd.concat([df_tend, df_tech, df_pais, df_mundo,df_eco,df_dep,df_cult], ignore_index=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tendencias</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tecnologias</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pais</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mundo</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economia</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deportes</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cultura</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  count(*)\n",
       "0   tendencias       300\n",
       "1  tecnologias       300\n",
       "2         pais       300\n",
       "3        mundo       300\n",
       "4     economia       300\n",
       "5     deportes       300\n",
       "6      cultura       300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=\"\"\"SELECT category, count(*) FROM df_train GROUP BY category ORDER BY count(*) DESC;\"\"\"\n",
    "test=sqldf(q)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nX = df_train['text'].astype(str)\\nylabels = df_train['category'].astype(str)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.25, random_state=0)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PRUEBAS REALES\n",
    "\n",
    "X = df['text'].astype(str)\n",
    "ylabels = df['category'].astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.25, random_state=0)\n",
    "\n",
    "## PRUEBAS PEQUEÑAS\n",
    "''' \n",
    "X = df_train['text'].astype(str)\n",
    "ylabels = df_train['category'].astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.25, random_state=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def feature_extraction(text):\n",
    "    \n",
    "    mytokens = nlp(text)\n",
    "\n",
    "    #Guardamos las palabras como características si corresponden a ciertas categorias gramaticaless\n",
    "    mytokens = [ word for word in mytokens if word.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"] ]\n",
    "    \n",
    "    #Transformamos las palabras en minusculas\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logistica utilizando CountVectorizer vs TFid \n",
    "\n",
    "\n",
    "##### Mejorar\n",
    "\n",
    "\n",
    "\n",
    "Al usar **countVectorizer**, utilizamos un enfoque `bag of word` por lo que creamos una matriz la cual tiene la siguente estructura:\n",
    "\n",
    "* Columnas: Todas las palabras que existen en el dataset\n",
    "* Filas: Textos del dataset\n",
    "\n",
    "Cada fila tiene un 1 si contiene la palabra indicada y un 0 en casos donde no.\n",
    "\n",
    "Al usar **TFid** cambiamos el enfoque bag of words a un enfoque `Term frequency (tf)` y `Inverse data frequency (idf)` por lo cual a la estructura anterior se le remplazaan los valores 1 y 0 por la frecuencia que tenga esa palabra en el texto de la fila.\n",
    "- A media qeu la palabra se repite más veces en la fila, tendrá un valor más alto y si no existe la palabra en la fila, tendrá un valor de 0.\n",
    "- Si la palabra se repite muchas veces en el dataset, el valor tambien aumenta.\n",
    "- Los valores difieren dependiendo de la cantidad de palabras que tenga la fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = feature_extraction, min_df=0., max_df=1.0)\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = feature_extraction, min_df=0., max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipe1 = Pipeline([('vectorizing', bow_vector),\n",
    "                 ('learning', model_1)])\n",
    "\n",
    "\n",
    "pipe2 = Pipeline([('vectorizing', tfidf_vector),\n",
    "                 ('learning', model_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizing',\n",
       "                 TfidfVectorizer(min_df=0.0,\n",
       "                                 tokenizer=<function feature_extraction at 0x7fd30808d5f0>)),\n",
       "                ('learning', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train,y_train)\n",
    "\n",
    "pipe2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_model_1 = pipe1.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_model_2 = pipe2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using CountVectorizer: 0.7222857142857143\n",
      "Logistic Regression using TfidfVectorizer: 0.772\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression using CountVectorizer:\",metrics.accuracy_score(y_test, predicted_model_1))\n",
    "\n",
    "print(\"Logistic Regression using TfidfVectorizer:\",metrics.accuracy_score(y_test, predicted_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión para CountVectorizer: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     cultura       0.59      0.97      0.74       250\n",
      "    deportes       0.86      0.78      0.82       255\n",
      "    economia       0.74      0.82      0.78       273\n",
      "       mundo       0.72      0.71      0.72       238\n",
      "        pais       0.80      0.58      0.68       250\n",
      " tecnologias       0.69      0.72      0.70       252\n",
      "  tendencias       0.79      0.43      0.56       232\n",
      "\n",
      "    accuracy                           0.72      1750\n",
      "   macro avg       0.74      0.72      0.71      1750\n",
      "weighted avg       0.74      0.72      0.72      1750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión para CountVectorizer: \")\n",
    "print(classification_report(y_test, predicted_model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión para TfidfVectorizer: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     cultura       0.87      0.90      0.89       250\n",
      "    deportes       0.85      0.87      0.86       255\n",
      "    economia       0.77      0.78      0.78       273\n",
      "       mundo       0.72      0.72      0.72       238\n",
      "        pais       0.78      0.68      0.72       250\n",
      " tecnologias       0.72      0.72      0.72       252\n",
      "  tendencias       0.69      0.72      0.70       232\n",
      "\n",
      "    accuracy                           0.77      1750\n",
      "   macro avg       0.77      0.77      0.77      1750\n",
      "weighted avg       0.77      0.77      0.77      1750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión para TfidfVectorizer: \")\n",
    "print(classification_report(y_test, predicted_model_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentarios\n",
    "* Comentar matriz de confusión, precision, recall, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
